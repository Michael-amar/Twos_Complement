{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # surpress warning and info messages\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense,Average\n",
    "from tensorflow.keras.regularizers import L2 as l2\n",
    "import tensorflow as tf\n",
    "from os.path import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append('../Model')\n",
    "sys.path.append('../DataGenerators')\n",
    "from base_model import build_transformer\n",
    "from data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_running_times(root):\n",
    "    with open(f'{root}POWER/metadata.json', 'r') as f: # the running time of both datasets are identical\n",
    "        metadata = json.load(f)\n",
    "        max =  metadata['max_running_time']\n",
    "        min =  metadata['min_running_time']\n",
    "        return max,min\n",
    "\n",
    "# builds a dataframe with the path and class of each sample\n",
    "def get_samples(root):\n",
    "    samples_df = pd.DataFrame(columns=[\"path\", \"class\", \"numeric_class\"])\n",
    "    samples_path = []\n",
    "    samples_class = []\n",
    "\n",
    "    for filename in glob.iglob(root + '**/*.npy', recursive=True):\n",
    "        clas = basename(dirname(filename)) # folder name is the name of the class\n",
    "        samples_path.append(filename)\n",
    "        samples_class.append(clas)\n",
    "\n",
    "    samples_df[\"path\"] = samples_path\n",
    "    samples_df[\"class\"] = samples_class\n",
    "\n",
    "    unique_classes = samples_df[\"class\"].copy().drop_duplicates().sort_values(ignore_index=True)\n",
    "    samples_df['numeric_class'] = samples_df['class'].apply(lambda class_name: unique_classes[unique_classes == class_name].index[0])\n",
    "\n",
    "    return samples_df, unique_classes\n",
    "\n",
    "def get_model(input_shape, n_classes):\n",
    "    inputs, intermediate_outputs = build_transformer(input_shape)\n",
    "    probs = Dense(n_classes, activation='sigmoid', kernel_regularizer=l2(0.0005))(intermediate_outputs)\n",
    "    model =  tf.keras.Model(inputs, probs)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "    # print(model.summary())\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "dataset_path = \"../testset/\"\n",
    "n_classes = 24\n",
    "noise_strength = 0\n",
    "\n",
    "max_running_time, min_running_time = get_running_times(dataset_path)\n",
    "\n",
    "em_samples_df, _ = get_samples(f'{dataset_path}EM/')\n",
    "power_samples_df, _ = get_samples(f'{dataset_path}POWER/')\n",
    "\n",
    "for noise_strength in range(0,21):\n",
    "    em_test_generator = DataGenerator(em_samples_df , n_classes=n_classes, max_running_time=max_running_time, min_running_time=min_running_time, win_size=3, sampling_rate=56000000, sigma=noise_strength)\n",
    "    power_test_generator = DataGenerator(power_samples_df , n_classes=n_classes, max_running_time=max_running_time, min_running_time=min_running_time, win_size=30, sampling_rate=1000000000, sigma=noise_strength)\n",
    "\n",
    "    em_input_shape = em_test_generator.get_shape()\n",
    "    power_input_shape = power_test_generator.get_shape()\n",
    "\n",
    "    # build model strcuture\n",
    "    em_model = get_model(em_input_shape, n_classes)\n",
    "    power_model = get_model(power_input_shape, n_classes)\n",
    "\n",
    "    # load model weights\n",
    "    em_model.load_weights(f\"../trained_models/single_channel/em_noise_{noise_strength}.hdf5\")\n",
    "    power_model.load_weights(f\"../trained_models/single_channel/power_noise_{noise_strength}.hdf5\")\n",
    "\n",
    "    em_test_probas = em_model.predict(em_test_generator, verbose=1)\n",
    "    power_test_probas = power_model.predict(power_test_generator, verbose=1)\n",
    "\n",
    "    # order of the samples is the same in the test generators\n",
    "    output_vector = ((em_test_probas + power_test_probas)/2)\n",
    "\n",
    "    y_pred = np.argmax(output_vector, axis=1)\n",
    "    y_true = em_test_generator.y_true\n",
    "\n",
    "    accuracy = sum(y_pred == y_true) / len(y_true)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Noise: {noise_strength}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,21), accuracies)\n",
    "plt.xlabel(f'Noise Sigma (\\u03c3)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
