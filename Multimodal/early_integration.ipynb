{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # surpress warning and info messages\n",
    "from tensorflow.keras.regularizers import L2 as l2\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from os.path import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append('../Model')\n",
    "sys.path.append('../DataGenerators')\n",
    "from base_model import build_transformer\n",
    "from fusion_data_generator import FusionDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_running_times(root):\n",
    "    with open(f'{root}POWER/metadata.json', 'r') as f: # the running time of both datasets are identical\n",
    "        metadata = json.load(f)\n",
    "        max =  metadata['max_running_time']\n",
    "        min =  metadata['min_running_time']\n",
    "        return max,min\n",
    "\n",
    "# builds a dataframe with the path and class of each sample\n",
    "def get_samples(root):\n",
    "    samples_df = pd.DataFrame(columns=[\"EM_path\", \"POWER_path\",\"class\", \"numeric_class\"])\n",
    "    power_samples_path = []\n",
    "    em_samples_path = []\n",
    "    samples_class = []\n",
    "\n",
    "    for filename in glob.iglob(f'{root}POWER/**/*.npy', recursive=True):\n",
    "        clas = basename(dirname(filename)) # folder name is the name of the class\n",
    "        power_sample_path = filename\n",
    "        power_samples_path.append(power_sample_path)\n",
    "        em_samples_path.append(power_sample_path.replace(\"POWER\",\"EM\"))\n",
    "        samples_class.append(clas)\n",
    "\n",
    "    samples_df[\"POWER_path\"] = power_samples_path\n",
    "    samples_df[\"EM_path\"] = em_samples_path\n",
    "    samples_df[\"class\"] = samples_class\n",
    "\n",
    "    unique_classes = samples_df[\"class\"].copy().drop_duplicates().sort_values(ignore_index=True)\n",
    "    samples_df['numeric_class'] = samples_df['class'].apply(lambda class_name: unique_classes[unique_classes == class_name].index[0])\n",
    "    \n",
    "    return samples_df, unique_classes\n",
    "\n",
    "def get_model(input_shape, n_classes):\n",
    "    concatenated_inputs, concatenated_embeddings = build_transformer(input_shape)\n",
    "    outputs = Dense(n_classes, activation='sigmoid', kernel_regularizer=l2(0.0005))(concatenated_embeddings)\n",
    "    model =  tf.keras.Model(concatenated_inputs, outputs)\n",
    "    model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    # print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "dataset_path = \"../testset/\"\n",
    "n_classes = 24\n",
    "\n",
    "for noise_strength in range(0,21):\n",
    "    trained_model_weights = f\"../trained_models/early_integration/em_noise_{noise_strength}_power_noise_{noise_strength}.hdf5\"\n",
    "    max_running_time, min_running_time  = get_running_times(dataset_path)\n",
    "    samples_df, classes_df = get_samples(dataset_path)\n",
    "    test_generator = FusionDataGenerator(samples_df, mode='early', n_classes=n_classes, max_running_time=max_running_time, min_running_time=min_running_time, sampling_rate_power=1000000000, sampling_rate_em=56000000, overlapping_percentage=None, em_noise_sigma=noise_strength, power_noise_sigma=noise_strength)\n",
    "\n",
    "    input_shape = test_generator.get_shape()\n",
    "\n",
    "    # build model structure\n",
    "    model = get_model(input_shape, n_classes)\n",
    "\n",
    "    # load model weights\n",
    "    model.load_weights(trained_model_weights)\n",
    "\n",
    "    y_test_pred_proba = model.predict(test_generator, verbose=1)\n",
    "\n",
    "    y_pred = np.argmax(y_test_pred_proba, axis=1)\n",
    "    y_true = test_generator.y_true\n",
    "\n",
    "    accuracy = sum(y_pred == y_true) / len(y_true)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Noise: {noise_strength}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,21), accuracies)\n",
    "plt.xlabel(f'Noise Sigma (\\u03c3)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
