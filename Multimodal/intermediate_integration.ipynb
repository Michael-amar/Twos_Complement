{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # surpress warning and info messages\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import L2 as l2\n",
    "from tensorflow.keras.layers import Dense, Layer, Reshape, Flatten, Dot, Softmax, concatenate\n",
    "import tensorflow as tf\n",
    "from os.path import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append('../Model')\n",
    "sys.path.append('../DataGenerators')\n",
    "from base_model import build_transformer\n",
    "from fusion_data_generator import FusionDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CrossAttentionLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(CrossAttentionLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        embedding_1, embedding_2 = inputs\n",
    "        \n",
    "        # Calculate attention weights\n",
    "        attention_weights = Dot(axes=-1, normalize=True)([embedding_2, embedding_1])\n",
    "        attention_weights = Softmax()(attention_weights)\n",
    "        \n",
    "        # Apply attention weights to embedding_1\n",
    "        attended_embedding_1 = Dot(axes=1)([attention_weights, embedding_1])\n",
    "        \n",
    "        return attended_embedding_1\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "def get_running_times(root):\n",
    "    with open(f'{root}POWER/metadata.json', 'r') as f: # the running time of both datasets are identical\n",
    "        metadata = json.load(f)\n",
    "        max =  metadata['max_running_time']\n",
    "        min =  metadata['min_running_time']\n",
    "        return max,min\n",
    "\n",
    "# builds a dataframe with the path and class of each sample\n",
    "def get_samples(root):\n",
    "    samples_df = pd.DataFrame(columns=[\"EM_path\", \"POWER_path\",\"class\", \"numeric_class\"])\n",
    "    power_samples_path = []\n",
    "    em_samples_path = []\n",
    "    samples_class = []\n",
    "\n",
    "    for filename in glob.iglob(f'{root}POWER/**/*.npy', recursive=True):\n",
    "        clas = basename(dirname(filename)) # folder name is the name of the class\n",
    "        power_sample_path = filename\n",
    "        power_samples_path.append(power_sample_path)\n",
    "        em_samples_path.append(power_sample_path.replace(\"POWER\",\"EM\"))\n",
    "        samples_class.append(clas)\n",
    "\n",
    "    samples_df[\"POWER_path\"] = power_samples_path\n",
    "    samples_df[\"EM_path\"] = em_samples_path\n",
    "    samples_df[\"class\"] = samples_class\n",
    "\n",
    "    unique_classes = samples_df[\"class\"].copy().drop_duplicates().sort_values(ignore_index=True)\n",
    "    samples_df['numeric_class'] = samples_df['class'].apply(lambda class_name: unique_classes[unique_classes == class_name].index[0])\n",
    "    \n",
    "    return samples_df, unique_classes\n",
    "\n",
    "def get_model(power_shape, em_shape, n_classes):\n",
    "    power_inputs, power_embeddings = build_transformer(power_shape)\n",
    "    em_inputs, em_embeddings = build_transformer(em_shape)\n",
    "\n",
    "    power_embeddings = Reshape(target_shape=(1,128))(power_embeddings)\n",
    "    em_embeddings = Reshape(target_shape=(1,128))(em_embeddings)\n",
    "    attended1 = CrossAttentionLayer()([power_embeddings, em_embeddings])\n",
    "    attended2 = CrossAttentionLayer()([em_embeddings, power_embeddings])\n",
    "    fused_embeddings = concatenate([attended1,attended2])\n",
    "    flat = Flatten()(fused_embeddings)\n",
    "    final_output = Dense(n_classes, activation='sigmoid', kernel_regularizer=l2(0.0005))(flat)\n",
    "    \n",
    "    model = tf.keras.Model([power_inputs, em_inputs], final_output)\n",
    "    model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    # print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "dataset_path = \"../testset/\"\n",
    "\n",
    "max_running_time, min_running_time  = get_running_times(dataset_path)\n",
    "samples_df, classes_df = get_samples(dataset_path)\n",
    "\n",
    "for noise_strength in range(0,21):\n",
    "    test_generator = FusionDataGenerator(samples_df, mode='intermediate', n_classes=24, max_running_time=max_running_time, min_running_time=min_running_time, sampling_rate_power=1000000000, sampling_rate_em=56000000, overlapping_percentage=0.6, em_noise_sigma=noise_strength, power_noise_sigma=noise_strength)\n",
    "\n",
    "    power_shape, em_shape = test_generator.get_shape()\n",
    "\n",
    "    # build model structure\n",
    "    model = get_model(power_shape, em_shape, 24)\n",
    "\n",
    "    # load model weights\n",
    "    model.load_weights(f\"../trained_models/intermediate_integration/em_noise_{noise_strength}_power_noise_{noise_strength}.hdf5\")\n",
    "\n",
    "    y_test_pred_proba = model.predict(test_generator, verbose=1)\n",
    "\n",
    "    y_pred = np.argmax(y_test_pred_proba, axis=1)\n",
    "    y_true = test_generator.y_true\n",
    "\n",
    "    accuracy = sum(y_pred == y_true) / len(y_true)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Noise: {noise_strength}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,21), accuracies)\n",
    "plt.xlabel(f'Noise Sigma (\\u03c3)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
